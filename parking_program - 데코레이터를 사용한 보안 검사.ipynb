{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ğŸš€ v7.0-388-g882c35fc Python-3.12.2 torch-2.5.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "'''# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "! pip install pytesseract\n",
    "! pip install opencv-python-headless\n",
    "! brew install tesseract-lang \n",
    "! pip install matplotlib\n",
    "! pip install opencv-python\n",
    "! pip install matplotlib\n",
    "! pip install torch torchvision torchaudio\n",
    "\n",
    "! git clone https://github.com/ultralytics/yolov5\n",
    "! pip install -r /Users/kyungrim/fake-license-plate-detection/yolov5/requirements.txt'''\n",
    "\n",
    "\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„ ì–¸\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'\n",
    "\n",
    "\n",
    "# YOLOv5 ëª¨ë¸ ë¡œë“œ\n",
    "model_path = './best.pt'\n",
    "model = torch.hub.load('./yolov5', 'custom', path=model_path, source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ë²ˆí˜¸íŒ</th>\n",
       "      <th>StoredHash</th>\n",
       "      <th>KeyPoints</th>\n",
       "      <th>Descriptors</th>\n",
       "      <th>ë‚´ë¶€ì¡´ì¬ì—¬ë¶€</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157ëª¨4876</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>(&lt; cv2.KeyPoint 0x178851080&gt;, &lt; cv2.KeyPoint 0...</td>\n",
       "      <td>[[165, 20, 24, 216, 237, 181, 68, 91, 85, 138,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05ë£¨7320</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>(&lt; cv2.KeyPoint 0x1761387e0&gt;, &lt; cv2.KeyPoint 0...</td>\n",
       "      <td>[[166, 223, 103, 75, 202, 53, 175, 252, 141, 3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ë²ˆí˜¸íŒ                                         StoredHash  \\\n",
       "0  157ëª¨4876  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1   05ë£¨7320  [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "\n",
       "                                           KeyPoints  \\\n",
       "0  (< cv2.KeyPoint 0x178851080>, < cv2.KeyPoint 0...   \n",
       "1  (< cv2.KeyPoint 0x1761387e0>, < cv2.KeyPoint 0...   \n",
       "\n",
       "                                         Descriptors  ë‚´ë¶€ì¡´ì¬ì—¬ë¶€  \n",
       "0  [[165, 20, 24, 216, 237, 181, 68, 91, 85, 138,...       0  \n",
       "1  [[166, 223, 103, 75, 202, 53, 175, 252, 141, 3...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í•¨ìˆ˜ ì„ ì–¸\n",
    "\n",
    "# ì°¨ëŸ‰ ì§„ì… (ì°¨ëŸ‰ ì´ë¯¸ì§€ ì…ë ¥)\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8, resize_dim=(800, 600)):\n",
    "    \"\"\"\n",
    "    íŒŒì¼ ê²½ë¡œë¥¼ ì½ì–´ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³ , í¬ê¸°ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "    :param filename: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "    :param flags: OpenCV ì´ë¯¸ì§€ ë¡œë“œ í”Œë˜ê·¸ (ê¸°ë³¸ê°’: cv2.IMREAD_COLOR)\n",
    "    :param dtype: ë°ì´í„° íƒ€ì… (ê¸°ë³¸ê°’: np.uint8)\n",
    "    :param resize_dim: ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ë„ˆë¹„, ë†’ì´)\n",
    "    :return: ë¡œë“œëœ ì´ë¯¸ì§€ ë˜ëŠ” None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)  # í•œê¸€ ê²½ë¡œ ì§€ì›ì„ ìœ„í•´ np.fromfile ì‚¬ìš©\n",
    "        img = cv2.imdecode(n, flags)     # ì´ë¯¸ì§€ ë””ì½”ë”©\n",
    "        if img is not None and resize_dim:  # ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ì—ˆê³  í¬ê¸° ì¡°ì • ì„¤ì •ì´ ìˆì„ ë•Œ\n",
    "            img = cv2.resize(img, resize_dim)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 1. ë²ˆí˜¸íŒ ì¸ì‹ & ë¹„êµ\n",
    "\n",
    "MAX_DIAG_MULTIPLYER = 5\n",
    "MAX_ANGLE_DIFF = 12.0\n",
    "MAX_AREA_DIFF = 0.5\n",
    "MAX_WIDTH_DIFF = 0.8\n",
    "MAX_HEIGHT_DIFF = 0.2\n",
    "MIN_N_MATCHED = 3\n",
    "\n",
    "def img_to_gray(image, image_show=True):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def detecting_car_plate(img) :\n",
    "    # YOLOv5ë¡œ ê°ì²´ íƒì§€\n",
    "    results = model(img)\n",
    "\n",
    "    detections = results.xyxy[0]  # íƒì§€ëœ ê°ì²´ì˜ ì¢Œí‘œ\n",
    "    for i, (*box, conf, cls) in enumerate(detections):\n",
    "        if int(cls) == 1:  # ë²ˆí˜¸íŒ í´ë˜ìŠ¤ë§Œ ì²˜ë¦¬\n",
    "            x1, y1, x2, y2 = map(int, box)  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ\n",
    "            cropped_plate = img[y1:y2, x1:x2]  # ë²ˆí˜¸íŒ ì˜ì—­ ìë¥´ê¸°\n",
    "\n",
    "    return cropped_plate\n",
    "    \n",
    "def extracting_car_number(img) :\n",
    "    # YOLOv5ë¡œ ê°ì²´ íƒì§€\n",
    "    img_ori = detecting_car_plate(img)\n",
    "\n",
    "    height, width, channel = img_ori.shape\n",
    "    channel = 1\n",
    "\n",
    "    # Morphology Operation\n",
    "    StructuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    topHat = cv2.morphologyEx(img_ori, cv2.MORPH_TOPHAT, StructuringElement)\n",
    "    blackHat = cv2.morphologyEx(img_ori, cv2.MORPH_BLACKHAT, StructuringElement)\n",
    "    img_topHat = cv2.add(img_ori, topHat)\n",
    "    img_ori = cv2.subtract(img_topHat, blackHat)\n",
    "    gray = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY)\n",
    "    # Gaussian Blurring\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "\n",
    "    # Adaptive Thresholding\n",
    "    img_blurred = cv2.GaussianBlur(gray, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "    img_blur_thresh = cv2.adaptiveThreshold(\n",
    "    img_blurred,\n",
    "    maxValue=255.0,\n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    thresholdType=cv2.THRESH_BINARY_INV,\n",
    "    blockSize=19,\n",
    "    C=9\n",
    "    )\n",
    "\n",
    "    img_blurred = cv2.GaussianBlur(gray, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "    img_blur_thresh = cv2.adaptiveThreshold(\n",
    "        img_blurred,\n",
    "        maxValue=255.0,\n",
    "        adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        thresholdType=cv2.THRESH_BINARY_INV,\n",
    "        blockSize=19,\n",
    "        C=11\n",
    "    )\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        img_blur_thresh,\n",
    "        mode=cv2.RETR_LIST,\n",
    "        method=cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    cv2.drawContours(temp_result, contours=contours, contourIdx=-1, color=(255,255,255))\n",
    "\n",
    "    temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    contours_dict = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(temp_result, pt1=(x,y), pt2=(x+w, y+h), color=(255,255,255), thickness=2)\n",
    "        \n",
    "        contours_dict.append({\n",
    "            'contour': contour,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'w': w,\n",
    "            'h': h,\n",
    "            'cx': x + (w / 2),\n",
    "            'cy': y + (h / 2)\n",
    "        })\n",
    "\n",
    "    MIN_AREA = 80\n",
    "    MIN_WIDTH, MIN_HEIGHT=2, 8\n",
    "    MIN_RATIO, MAX_RATIO = 0.2, 1.0\n",
    "\n",
    "    possible_contours = []\n",
    "\n",
    "    cnt = 0\n",
    "    for d in contours_dict:\n",
    "        area = d['w'] * d['h']\n",
    "        ratio = d['w'] / d['h']\n",
    "        \n",
    "        if area > MIN_AREA \\\n",
    "        and d['w'] > MIN_WIDTH and d['h'] > MIN_HEIGHT \\\n",
    "        and MIN_RATIO < ratio < MAX_RATIO:\n",
    "            d['idx'] = cnt\n",
    "            cnt += 1\n",
    "            possible_contours.append(d)\n",
    "\n",
    "    temp_result = np.zeros((height, width, channel), dtype = np.uint8)\n",
    "\n",
    "    for d in possible_contours:\n",
    "        cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255, 255, 255), thickness=2)\n",
    "\n",
    "    def find_chars(contour_list):\n",
    "        matched_result_idx = []\n",
    "        \n",
    "        for d1 in contour_list:\n",
    "            matched_contours_idx = []\n",
    "            for d2 in contour_list:\n",
    "                if d1['idx'] == d2['idx']:\n",
    "                    continue\n",
    "                    \n",
    "                dx = abs(d1['cx'] - d2['cx'])\n",
    "                dy = abs(d1['cy'] - d2['cy'])\n",
    "                \n",
    "                diagonal_length1 = np.sqrt(d1['w'] ** 2 + d1['h'] ** 2)\n",
    "                \n",
    "                distance = np.linalg.norm(np.array([d1['cx'], d1['cy']]) - np.array([d2['cx'], d2['cy']]))\n",
    "                if dx == 0:\n",
    "                    angle_diff = 90\n",
    "                else:\n",
    "                    angle_diff = np.degrees(np.arctan(dy / dx))\n",
    "                area_diff = abs(d1['w'] * d1['h'] - d2['w'] * d2['h']) / (d1['w'] * d1['h'])\n",
    "                width_diff = abs(d1['w'] - d2['w']) / d1['w']\n",
    "                height_diff = abs(d1['h'] - d2['h']) / d1['h']\n",
    "                \n",
    "                if distance < diagonal_length1 * MAX_DIAG_MULTIPLYER \\\n",
    "                and angle_diff < MAX_ANGLE_DIFF and area_diff < MAX_AREA_DIFF \\\n",
    "                and width_diff < MAX_WIDTH_DIFF and height_diff < MAX_HEIGHT_DIFF:\n",
    "                    matched_contours_idx.append(d2['idx'])\n",
    "                    \n",
    "            matched_contours_idx.append(d1['idx'])\n",
    "            \n",
    "            if len(matched_contours_idx) < MIN_N_MATCHED:\n",
    "                continue\n",
    "                \n",
    "            matched_result_idx.append(matched_contours_idx)\n",
    "            \n",
    "            unmatched_contour_idx = []\n",
    "            for d4 in contour_list:\n",
    "                if d4['idx'] not in matched_contours_idx:\n",
    "                    unmatched_contour_idx.append(d4['idx'])\n",
    "            \n",
    "            unmatched_contour = np.take(possible_contours, unmatched_contour_idx)\n",
    "            \n",
    "            recursive_contour_list = find_chars(unmatched_contour)\n",
    "            \n",
    "            for idx in recursive_contour_list:\n",
    "                matched_result_idx.append(idx)\n",
    "                \n",
    "            break\n",
    "            \n",
    "        return matched_result_idx\n",
    "\n",
    "    result_idx = find_chars(possible_contours)\n",
    "\n",
    "    matched_result = []\n",
    "    for idx_list in result_idx:\n",
    "        matched_result.append(np.take(possible_contours, idx_list))\n",
    "        \n",
    "    temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    for r in matched_result:\n",
    "        for d in r:\n",
    "            cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255,255,255), thickness=2)\n",
    "\n",
    "    PLATE_WIDTH_PADDING = 1.3 # 1.3\n",
    "    PLATE_HEIGHT_PADDING = 1.5 # 1.5\n",
    "    MIN_PLATE_RATIO = 3\n",
    "    MAX_PLATE_RATIO = 10\n",
    "\n",
    "    plate_imgs = []\n",
    "    plate_infos = []\n",
    "\n",
    "    for i, matched_chars in enumerate(matched_result):\n",
    "        sorted_chars = sorted(matched_chars, key=lambda x: x['cx'])\n",
    "\n",
    "        plate_cx = (sorted_chars[0]['cx'] + sorted_chars[-1]['cx']) / 2\n",
    "        plate_cy = (sorted_chars[0]['cy'] + sorted_chars[-1]['cy']) / 2\n",
    "        \n",
    "        plate_width = (sorted_chars[-1]['x'] + sorted_chars[-1]['w'] - sorted_chars[0]['x']) * PLATE_WIDTH_PADDING\n",
    "        \n",
    "        sum_height = 0\n",
    "        for d in sorted_chars:\n",
    "            sum_height += d['h']\n",
    "\n",
    "        plate_height = int(sum_height / len(sorted_chars) * PLATE_HEIGHT_PADDING)\n",
    "        \n",
    "        triangle_height = sorted_chars[-1]['cy'] - sorted_chars[0]['cy']\n",
    "        triangle_hypotenus = np.linalg.norm(\n",
    "            np.array([sorted_chars[0]['cx'], sorted_chars[0]['cy']]) - \n",
    "            np.array([sorted_chars[-1]['cx'], sorted_chars[-1]['cy']])\n",
    "        )\n",
    "        \n",
    "        angle = np.degrees(np.arcsin(triangle_height / triangle_hypotenus))\n",
    "        \n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center=(plate_cx, plate_cy), angle=angle, scale=1.0)\n",
    "        \n",
    "        img_rotated = cv2.warpAffine(img_blur_thresh, M=rotation_matrix, dsize=(width, height))\n",
    "        \n",
    "        img_cropped = cv2.getRectSubPix(\n",
    "            img_rotated, \n",
    "            patchSize=(int(plate_width), int(plate_height)), \n",
    "            center=(int(plate_cx), int(plate_cy))\n",
    "        )\n",
    "        \n",
    "        if img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO or img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO > MAX_PLATE_RATIO:\n",
    "            continue\n",
    "        \n",
    "        plate_imgs.append(img_cropped)\n",
    "        plate_infos.append({\n",
    "            'x': int(plate_cx - plate_width / 2),\n",
    "            'y': int(plate_cy - plate_height / 2),\n",
    "            'w': int(plate_width),\n",
    "            'h': int(plate_height)\n",
    "        })\n",
    "\n",
    "    longest_idx, longest_text = -1, 0\n",
    "    plate_chars = []\n",
    "\n",
    "    for i, plate_img in enumerate(plate_imgs):\n",
    "        plate_img = cv2.resize(plate_img, dsize=(0, 0), fx=1.6, fy=1.6)\n",
    "        _, plate_img = cv2.threshold(plate_img, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        \n",
    "        # find contours again (same as above)\n",
    "        contours, _ = cv2.findContours(plate_img, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        plate_min_x, plate_min_y = plate_img.shape[1], plate_img.shape[0]\n",
    "        plate_max_x, plate_max_y = 0, 0\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            area = w * h\n",
    "            ratio = w / h\n",
    "\n",
    "            if area > MIN_AREA \\\n",
    "            and w > MIN_WIDTH and h > MIN_HEIGHT \\\n",
    "            and MIN_RATIO < ratio < MAX_RATIO:\n",
    "                if x < plate_min_x:\n",
    "                    plate_min_x = x\n",
    "                if y < plate_min_y:\n",
    "                    plate_min_y = y\n",
    "                if x + w > plate_max_x:\n",
    "                    plate_max_x = x + w\n",
    "                if y + h > plate_max_y:\n",
    "                    plate_max_y = y + h\n",
    "                    \n",
    "        img_result = plate_img[plate_min_y:plate_max_y, plate_min_x:plate_max_x]\n",
    "        \n",
    "        img_result = cv2.GaussianBlur(img_result, ksize=(3, 3), sigmaX=0)\n",
    "        _, img_result = cv2.threshold(img_result, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        img_result = cv2.copyMakeBorder(img_result, top=10, bottom=10, left=10, right=10, borderType=cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "        \n",
    "        chars = pytesseract.image_to_string(img_result, lang='kornum+kor', config='--psm 6 preserve_interword_spaces')\n",
    "        #chars = pytesseract.image_to_string(img_result, lang='kornum+kor', config='--psm 7 --oem 3')\n",
    "        \n",
    "        result_chars = ''\n",
    "        has_digit = False\n",
    "        for c in chars:\n",
    "            if ord('ê°€') <= ord(c) <= ord('í£') or c.isdigit():\n",
    "                if c.isdigit():\n",
    "                    has_digit = True\n",
    "                result_chars += c\n",
    "        \n",
    "        plate_chars.append(result_chars)\n",
    "\n",
    "        if has_digit and len(result_chars) > longest_text:\n",
    "            longest_idx = i\n",
    "\n",
    "    return result_chars\n",
    "\n",
    "def is_car_number_in_database(extracted_number, database_numbers):\n",
    "    return any(extracted_number in db_number or db_number in extracted_number for db_number in database_numbers)\n",
    "\n",
    "# ìœ ì‚¬ ë²ˆí˜¸íŒ ì°¾ê¸° í•¨ìˆ˜\n",
    "def find_closest_plate(entering_number, database_numbers):\n",
    "    # ì…ë ¥ëœ ë²ˆí˜¸íŒê³¼ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë²ˆí˜¸íŒì„ ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ë²ˆí˜¸íŒì„ ë°˜í™˜\n",
    "    for db_number in database_numbers:\n",
    "        if entering_number in db_number or db_number in entering_number:\n",
    "            return db_number\n",
    "    return None\n",
    "\n",
    "\n",
    "# 2. ì´ë¯¸ì§€ ë§¤ì¹­ & ë¹„êµ\n",
    "\n",
    "def img2hash(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (600, 300))\n",
    "    avg = gray.mean()\n",
    "    bi = 1 * (gray > avg)\n",
    "    return bi\n",
    "\n",
    "def hamming_distance(a, b):\n",
    "    a = a.reshape(1,-1)\n",
    "    b = b.reshape(1,-1)\n",
    "    # ê°™ì€ ìë¦¬ì˜ ê°’ì´ ì„œë¡œ ë‹¤ë¥¸ ê²ƒë“¤ì˜ í•©\n",
    "    distance = (a !=b).sum()\n",
    "    return distance\n",
    "\n",
    "matching_criterion = 250\n",
    "desc_criterion = 70\n",
    "def image_match(image, stored_hash):\n",
    "    # ë“¤ì–´ì˜¨ ì°¨ëŸ‰ì˜ ì´ë¯¸ì§€\n",
    "    income_car_image = image    \n",
    "    # ì°¨ ì˜ìƒì˜ í•´ì‰¬ êµ¬í•˜ê¸°\n",
    "    query_hash = img2hash(income_car_image)\n",
    "    \n",
    "    # í•´ë‹¹ ì°¨ëŸ‰ì˜ ì €ì¥ëœ í•´ì‰¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    stored_hash = stored_hash\n",
    "    \n",
    "    # í•´ë° ê±°ë¦¬ ì‚°ì¶œ\n",
    "    flag = 0\n",
    "    hamming_dst = hamming_distance(query_hash, stored_hash)\n",
    "    if hamming_dst/256 < matching_criterion: flag=1; print(f'  Â·Â·Â·ì´ë¯¸ì§€ ë§¤ì¹­ëŸ‰ : {hamming_dst/256}'); print('  Â·Â·Â·ë™ì¼ ì°¨ëŸ‰ì…ë‹ˆë‹¤.')\n",
    "    else: print(f'  Â·Â·Â·ì´ë¯¸ì§€ ë§¤ì¹­ëŸ‰ : {hamming_dst/256}'); print('  Â·Â·Â·ë™ì¼í•˜ì§€ ì•Šì€ ì°¨ëŸ‰ì…ë‹ˆë‹¤.')\n",
    "        \n",
    "    return income_car_image, flag\n",
    "\n",
    "\n",
    "\n",
    "# 3. íŠ¹ì§•ì  ë§¤ì¹­ & ë¹„êµ\n",
    "\n",
    "# ORBë¡œ ì„œìˆ ì ì¶”ì¶œ \n",
    "detector = cv2.ORB_create()\n",
    "# BF-Hamming ìƒì„±\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING2)\n",
    "\n",
    "def get_desc(img):\n",
    "    img = img\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kp, desc = detector.detectAndCompute(gray, None)\n",
    "    return kp, desc\n",
    "\n",
    "def ORB_knnMatch(income_car_image, flag, stored_kp, stored_desc):\n",
    "    # ê° ì˜ìƒì— ëŒ€í•´ í‚¤ í¬ì¸íŠ¸ì™€ ì„œìˆ ì ì¶”ì¶œ \n",
    "    compare_kp, compare_desc = get_desc(income_car_image)\n",
    "    # knnMatch, k=2\n",
    "    matches = matcher.knnMatch(compare_desc, stored_desc, 2)\n",
    "\n",
    "    # ì²«ë²ˆì¬ ì´ì›ƒì˜ ê±°ë¦¬ê°€ ë‘ ë²ˆì§¸ ì´ì›ƒ ê±°ë¦¬ì˜ 75% ì´ë‚´ì¸ ê²ƒë§Œ ì¶”ì¶œ---â‘¤\n",
    "    ratio = 0.75; desc_flag = 0\n",
    "    good_matches = [first for first,second in matches \\\n",
    "                        if first.distance < second.distance * ratio]\n",
    "    if len(good_matches) > desc_criterion: desc_flag = 1; print('  Â·Â·Â·ë™ì¼ ì°¨ëŸ‰ì…ë‹ˆë‹¤.')\n",
    "    else: print('  Â·Â·Â·ë™ì¼í•˜ì§€ ì•Šì€ ì°¨ëŸ‰ì…ë‹ˆë‹¤')\n",
    "    print(f'  Â·Â·Â·íŠ¹ì§•ì  ë§¤ì¹­ëŸ‰ : {len(good_matches)}/{len(matches)}')\n",
    "    return desc_flag\n",
    "\n",
    "\n",
    "# 4. ë‚´ë¶€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "car1 = cv2.imread('/Users/kyungrim/fake-license-plate-detection/test_car/lightcar1.jpg')\n",
    "car2 = cv2.imread('/Users/kyungrim/fake-license-plate-detection/test_car/whitecar1.jpg')\n",
    "\n",
    "car1_kp, car1_desc = get_desc(car1)\n",
    "car2_kp, car2_desc = get_desc(car2)\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ (ì˜ˆì‹œ)\n",
    "database = pd.DataFrame({\n",
    "    'ë²ˆí˜¸íŒ' : [extracting_car_number(car1), extracting_car_number(car2)],\n",
    "    'StoredHash' : [img2hash(car1), img2hash(car2)],\n",
    "    'KeyPoints' : [car1_kp, car2_kp],\n",
    "    'Descriptors' : [car1_desc, car2_desc],\n",
    "    'ë‚´ë¶€ì¡´ì¬ì—¬ë¶€' : [0, 0]\n",
    "})\n",
    "\n",
    "\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car :\n",
    "    def __init__(self, img) :\n",
    "        self.car_number = extracting_car_number(img)\n",
    "        self.hash = img2hash(img)\n",
    "        self.kp, self.desc = get_desc(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì½”ë ˆì´í„° ì •ì˜\n",
    "def security_check(step_name):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            global cnt  # ì „ì—­ ë³€ìˆ˜ cnt ì ‘ê·¼\n",
    "            print(f\"ê²€ì‚¬ ì‹œì‘: {step_name}\")\n",
    "            result = func(*args, **kwargs)\n",
    "            if result:\n",
    "                print(f\"í†µê³¼: {step_name}\")\n",
    "                cnt += 1\n",
    "            else:\n",
    "                print(f\"ì‹¤íŒ¨: {step_name}\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# ë³´ì•ˆ ê²€ì‚¬ ì½”ë“œì— ë°ì½”ë ˆì´í„° ì ìš©\n",
    "@security_check(\"ë²ˆí˜¸íŒ ë“±ë¡ ì—¬ë¶€ í™•ì¸\")\n",
    "def check_car_registration(car_number, database):\n",
    "    return is_car_number_in_database(car_number, database['ë²ˆí˜¸íŒ'].tolist())\n",
    "\n",
    "@security_check(\"ì´ë¯¸ì§€ ë§¤ì¹­ í™•ì¸\")\n",
    "def check_image_match(car_image, stored_hash):\n",
    "    _, flag = image_match(car_image, stored_hash)\n",
    "    return flag == 1\n",
    "\n",
    "@security_check(\"íŠ¹ì§•ì  ë§¤ì¹­ í™•ì¸\")\n",
    "def check_feature_match(car_image, stored_kp, stored_desc):\n",
    "    return ORB_knnMatch(car_image, 1, stored_kp, stored_desc)  # flagëŠ” 1ë¡œ ì„¤ì •\n",
    "\n",
    "@security_check(\"ë‚´ë¶€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\")\n",
    "def check_internal_presence(closest_plate, database):\n",
    "    return database.loc[database['ë²ˆí˜¸íŒ'] == closest_plate, 'ë‚´ë¶€ì¡´ì¬ì—¬ë¶€'].values[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§„ì…í•œ ì°¨ëŸ‰ì˜ ì‚¬ì§„ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§„ì…í•œ ì°¨ëŸ‰ì˜ ë²ˆí˜¸íŒ: 157ëª¨48761\n",
      "ê²€ì‚¬ ì‹œì‘: ë²ˆí˜¸íŒ ë“±ë¡ ì—¬ë¶€ í™•ì¸\n",
      "í†µê³¼: ë²ˆí˜¸íŒ ë“±ë¡ ì—¬ë¶€ í™•ì¸\n",
      "ê²€ì‚¬ ì‹œì‘: ì´ë¯¸ì§€ ë§¤ì¹­ í™•ì¸\n",
      "  Â·Â·Â·ì´ë¯¸ì§€ ë§¤ì¹­ëŸ‰ : 205.078125\n",
      "  Â·Â·Â·ë™ì¼ ì°¨ëŸ‰ì…ë‹ˆë‹¤.\n",
      "í†µê³¼: ì´ë¯¸ì§€ ë§¤ì¹­ í™•ì¸\n",
      "ê²€ì‚¬ ì‹œì‘: íŠ¹ì§•ì  ë§¤ì¹­ í™•ì¸\n",
      "  Â·Â·Â·ë™ì¼ ì°¨ëŸ‰ì…ë‹ˆë‹¤.\n",
      "  Â·Â·Â·íŠ¹ì§•ì  ë§¤ì¹­ëŸ‰ : 94/500\n",
      "í†µê³¼: íŠ¹ì§•ì  ë§¤ì¹­ í™•ì¸\n",
      "ê²€ì‚¬ ì‹œì‘: ë‚´ë¶€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
      "í†µê³¼: ë‚´ë¶€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
      "ğŸš˜ ëª¨ë“  ë³´ì•ˆì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤. ì§„ì…í•˜ì‹­ì‹œì˜¤. ğŸš˜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "print(\"ì§„ì…í•œ ì°¨ëŸ‰ì˜ ì‚¬ì§„ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.\")\n",
    "car_image = imread('/Users/kyungrim/fake-license-plate-detection/test_car/lightcar2.jpg')\n",
    "entering_car = Car(car_image)\n",
    "cnt = 0  # í†µê³¼ ë‹¨ê³„ count\n",
    "\n",
    "# ë²ˆí˜¸íŒ ì¸ì‹\n",
    "cropped_plate = detecting_car_plate(car_image)\n",
    "car_number = entering_car.car_number\n",
    "if car_number:\n",
    "    print(\"ì§„ì…í•œ ì°¨ëŸ‰ì˜ ë²ˆí˜¸íŒ:\", car_number)\n",
    "\n",
    "# 1. ë²ˆí˜¸íŒ ë“±ë¡ ì—¬ë¶€ í™•ì¸\n",
    "check_car_registration(car_number, database)\n",
    "\n",
    "# ê°€ì¥ ìœ ì‚¬í•œ ë²ˆí˜¸íŒ ì°¾ê¸°\n",
    "closest_plate = find_closest_plate(car_number, database['ë²ˆí˜¸íŒ'].tolist())\n",
    "\n",
    "# 2. ì´ë¯¸ì§€ ë§¤ì¹­ í™•ì¸\n",
    "stored_hash = database.loc[database['ë²ˆí˜¸íŒ'] == closest_plate, 'StoredHash'].values[0]\n",
    "check_image_match(car_image, stored_hash)\n",
    "\n",
    "# 3. íŠ¹ì§•ì  ë§¤ì¹­ í™•ì¸\n",
    "stored_kp = database.loc[database['ë²ˆí˜¸íŒ'] == closest_plate, 'KeyPoints'].values[0]\n",
    "stored_desc = database.loc[database['ë²ˆí˜¸íŒ'] == closest_plate, 'Descriptors'].values[0]\n",
    "check_feature_match(car_image, stored_kp, stored_desc)\n",
    "\n",
    "# 4. ë‚´ë¶€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "check_internal_presence(closest_plate, database)\n",
    "\n",
    "# ìµœì¢… ì§„ì… ì—¬ë¶€ íŒë‹¨\n",
    "if cnt == 4:\n",
    "    print(\"ğŸš˜ ëª¨ë“  ë³´ì•ˆì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤. ì§„ì…í•˜ì‹­ì‹œì˜¤. ğŸš˜\")\n",
    "else:\n",
    "    print(\"âŒ ë³´ì•ˆì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¶œì°¨í•˜ì‹­ì‹œì˜¤. âŒ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
