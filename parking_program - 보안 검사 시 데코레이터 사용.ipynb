{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ v7.0-388-g882c35fc Python-3.12.2 torch-2.5.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "'''# ÌïÑÏöî ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò\n",
    "! pip install pytesseract\n",
    "! pip install opencv-python-headless\n",
    "! brew install tesseract-lang \n",
    "! pip install matplotlib\n",
    "! pip install opencv-python\n",
    "! pip install matplotlib\n",
    "! pip install torch torchvision torchaudio\n",
    "\n",
    "! git clone https://github.com/ultralytics/yolov5\n",
    "! pip install -r /Users/kyungrim/fake-license-plate-detection/yolov5/requirements.txt'''\n",
    "\n",
    "\n",
    "# ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ†Ïñ∏\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/opt/homebrew/bin/tesseract'\n",
    "\n",
    "\n",
    "# YOLOv5 Î™®Îç∏ Î°úÎìú\n",
    "model_path = './best.pt'\n",
    "model = torch.hub.load('./yolov5', 'custom', path=model_path, source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Î≤àÌò∏Ìåê</th>\n",
       "      <th>StoredHash</th>\n",
       "      <th>KeyPoints</th>\n",
       "      <th>Descriptors</th>\n",
       "      <th>ÎÇ¥Î∂ÄÏ°¥Ïû¨Ïó¨Î∂Ä</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157Î™®4876</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>(&lt; cv2.KeyPoint 0x178851080&gt;, &lt; cv2.KeyPoint 0...</td>\n",
       "      <td>[[165, 20, 24, 216, 237, 181, 68, 91, 85, 138,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05Î£®7320</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>(&lt; cv2.KeyPoint 0x1761387e0&gt;, &lt; cv2.KeyPoint 0...</td>\n",
       "      <td>[[166, 223, 103, 75, 202, 53, 175, 252, 141, 3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Î≤àÌò∏Ìåê                                         StoredHash  \\\n",
       "0  157Î™®4876  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1   05Î£®7320  [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "\n",
       "                                           KeyPoints  \\\n",
       "0  (< cv2.KeyPoint 0x178851080>, < cv2.KeyPoint 0...   \n",
       "1  (< cv2.KeyPoint 0x1761387e0>, < cv2.KeyPoint 0...   \n",
       "\n",
       "                                         Descriptors  ÎÇ¥Î∂ÄÏ°¥Ïû¨Ïó¨Î∂Ä  \n",
       "0  [[165, 20, 24, 216, 237, 181, 68, 91, 85, 138,...       0  \n",
       "1  [[166, 223, 103, 75, 202, 53, 175, 252, 141, 3...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ìï®Ïàò ÏÑ†Ïñ∏\n",
    "\n",
    "# Ï∞®Îüâ ÏßÑÏûÖ (Ï∞®Îüâ Ïù¥ÎØ∏ÏßÄ ÏûÖÎ†•)\n",
    "def imread(filename, flags=cv2.IMREAD_COLOR, dtype=np.uint8, resize_dim=(800, 600)):\n",
    "    \"\"\"\n",
    "    ÌååÏùº Í≤ΩÎ°úÎ•º ÏùΩÏñ¥ Ïù¥ÎØ∏ÏßÄÎ•º Î°úÎìúÌïòÍ≥†, ÌÅ¨Í∏∞Î•º Ï°∞Ï†ïÌï©ÎãàÎã§.\n",
    "    :param filename: Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú\n",
    "    :param flags: OpenCV Ïù¥ÎØ∏ÏßÄ Î°úÎìú ÌîåÎûòÍ∑∏ (Í∏∞Î≥∏Í∞í: cv2.IMREAD_COLOR)\n",
    "    :param dtype: Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ (Í∏∞Î≥∏Í∞í: np.uint8)\n",
    "    :param resize_dim: Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ Ï°∞Ï†ï (ÎÑàÎπÑ, ÎÜíÏù¥)\n",
    "    :return: Î°úÎìúÎêú Ïù¥ÎØ∏ÏßÄ ÎòêÎäî None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        n = np.fromfile(filename, dtype)  # ÌïúÍ∏Ä Í≤ΩÎ°ú ÏßÄÏõêÏùÑ ÏúÑÌï¥ np.fromfile ÏÇ¨Ïö©\n",
    "        img = cv2.imdecode(n, flags)     # Ïù¥ÎØ∏ÏßÄ ÎîîÏΩîÎî©\n",
    "        if img is not None and resize_dim:  # Ïù¥ÎØ∏ÏßÄÍ∞Ä Î°úÎìúÎêòÏóàÍ≥† ÌÅ¨Í∏∞ Ï°∞Ï†ï ÏÑ§Ï†ïÏù¥ ÏûàÏùÑ Îïå\n",
    "            img = cv2.resize(img, resize_dim)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# 1. Î≤àÌò∏Ìåê Ïù∏Ïãù & ÎπÑÍµê\n",
    "\n",
    "MAX_DIAG_MULTIPLYER = 5\n",
    "MAX_ANGLE_DIFF = 12.0\n",
    "MAX_AREA_DIFF = 0.5\n",
    "MAX_WIDTH_DIFF = 0.8\n",
    "MAX_HEIGHT_DIFF = 0.2\n",
    "MIN_N_MATCHED = 3\n",
    "\n",
    "def img_to_gray(image, image_show=True):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "\n",
    "def detecting_car_plate(img) :\n",
    "    # YOLOv5Î°ú Í∞ùÏ≤¥ ÌÉêÏßÄ\n",
    "    results = model(img)\n",
    "\n",
    "    detections = results.xyxy[0]  # ÌÉêÏßÄÎêú Í∞ùÏ≤¥Ïùò Ï¢åÌëú\n",
    "    for i, (*box, conf, cls) in enumerate(detections):\n",
    "        if int(cls) == 1:  # Î≤àÌò∏Ìåê ÌÅ¥ÎûòÏä§Îßå Ï≤òÎ¶¨\n",
    "            x1, y1, x2, y2 = map(int, box)  # Î∞îÏö¥Îî© Î∞ïÏä§ Ï¢åÌëú\n",
    "            cropped_plate = img[y1:y2, x1:x2]  # Î≤àÌò∏Ìåê ÏòÅÏó≠ ÏûêÎ•¥Í∏∞\n",
    "\n",
    "    return cropped_plate\n",
    "    \n",
    "def extracting_car_number(img) :\n",
    "    # YOLOv5Î°ú Í∞ùÏ≤¥ ÌÉêÏßÄ\n",
    "    img_ori = detecting_car_plate(img)\n",
    "\n",
    "    height, width, channel = img_ori.shape\n",
    "    channel = 1\n",
    "\n",
    "    # Morphology Operation\n",
    "    StructuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    topHat = cv2.morphologyEx(img_ori, cv2.MORPH_TOPHAT, StructuringElement)\n",
    "    blackHat = cv2.morphologyEx(img_ori, cv2.MORPH_BLACKHAT, StructuringElement)\n",
    "    img_topHat = cv2.add(img_ori, topHat)\n",
    "    img_ori = cv2.subtract(img_topHat, blackHat)\n",
    "    gray = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY)\n",
    "    # Gaussian Blurring\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 2)\n",
    "\n",
    "    # Adaptive Thresholding\n",
    "    img_blurred = cv2.GaussianBlur(gray, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "    img_blur_thresh = cv2.adaptiveThreshold(\n",
    "    img_blurred,\n",
    "    maxValue=255.0,\n",
    "    adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "    thresholdType=cv2.THRESH_BINARY_INV,\n",
    "    blockSize=19,\n",
    "    C=9\n",
    "    )\n",
    "\n",
    "    img_blurred = cv2.GaussianBlur(gray, ksize=(5, 5), sigmaX=0)\n",
    "\n",
    "    img_blur_thresh = cv2.adaptiveThreshold(\n",
    "        img_blurred,\n",
    "        maxValue=255.0,\n",
    "        adaptiveMethod=cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        thresholdType=cv2.THRESH_BINARY_INV,\n",
    "        blockSize=19,\n",
    "        C=11\n",
    "    )\n",
    "\n",
    "    contours, _ = cv2.findContours(\n",
    "        img_blur_thresh,\n",
    "        mode=cv2.RETR_LIST,\n",
    "        method=cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    cv2.drawContours(temp_result, contours=contours, contourIdx=-1, color=(255,255,255))\n",
    "\n",
    "    temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    contours_dict = []\n",
    "\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(temp_result, pt1=(x,y), pt2=(x+w, y+h), color=(255,255,255), thickness=2)\n",
    "        \n",
    "        contours_dict.append({\n",
    "            'contour': contour,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'w': w,\n",
    "            'h': h,\n",
    "            'cx': x + (w / 2),\n",
    "            'cy': y + (h / 2)\n",
    "        })\n",
    "\n",
    "    MIN_AREA = 80\n",
    "    MIN_WIDTH, MIN_HEIGHT=2, 8\n",
    "    MIN_RATIO, MAX_RATIO = 0.2, 1.0\n",
    "\n",
    "    possible_contours = []\n",
    "\n",
    "    cnt = 0\n",
    "    for d in contours_dict:\n",
    "        area = d['w'] * d['h']\n",
    "        ratio = d['w'] / d['h']\n",
    "        \n",
    "        if area > MIN_AREA \\\n",
    "        and d['w'] > MIN_WIDTH and d['h'] > MIN_HEIGHT \\\n",
    "        and MIN_RATIO < ratio < MAX_RATIO:\n",
    "            d['idx'] = cnt\n",
    "            cnt += 1\n",
    "            possible_contours.append(d)\n",
    "\n",
    "    temp_result = np.zeros((height, width, channel), dtype = np.uint8)\n",
    "\n",
    "    for d in possible_contours:\n",
    "        cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255, 255, 255), thickness=2)\n",
    "\n",
    "    def find_chars(contour_list):\n",
    "        matched_result_idx = []\n",
    "        \n",
    "        for d1 in contour_list:\n",
    "            matched_contours_idx = []\n",
    "            for d2 in contour_list:\n",
    "                if d1['idx'] == d2['idx']:\n",
    "                    continue\n",
    "                    \n",
    "                dx = abs(d1['cx'] - d2['cx'])\n",
    "                dy = abs(d1['cy'] - d2['cy'])\n",
    "                \n",
    "                diagonal_length1 = np.sqrt(d1['w'] ** 2 + d1['h'] ** 2)\n",
    "                \n",
    "                distance = np.linalg.norm(np.array([d1['cx'], d1['cy']]) - np.array([d2['cx'], d2['cy']]))\n",
    "                if dx == 0:\n",
    "                    angle_diff = 90\n",
    "                else:\n",
    "                    angle_diff = np.degrees(np.arctan(dy / dx))\n",
    "                area_diff = abs(d1['w'] * d1['h'] - d2['w'] * d2['h']) / (d1['w'] * d1['h'])\n",
    "                width_diff = abs(d1['w'] - d2['w']) / d1['w']\n",
    "                height_diff = abs(d1['h'] - d2['h']) / d1['h']\n",
    "                \n",
    "                if distance < diagonal_length1 * MAX_DIAG_MULTIPLYER \\\n",
    "                and angle_diff < MAX_ANGLE_DIFF and area_diff < MAX_AREA_DIFF \\\n",
    "                and width_diff < MAX_WIDTH_DIFF and height_diff < MAX_HEIGHT_DIFF:\n",
    "                    matched_contours_idx.append(d2['idx'])\n",
    "                    \n",
    "            matched_contours_idx.append(d1['idx'])\n",
    "            \n",
    "            if len(matched_contours_idx) < MIN_N_MATCHED:\n",
    "                continue\n",
    "                \n",
    "            matched_result_idx.append(matched_contours_idx)\n",
    "            \n",
    "            unmatched_contour_idx = []\n",
    "            for d4 in contour_list:\n",
    "                if d4['idx'] not in matched_contours_idx:\n",
    "                    unmatched_contour_idx.append(d4['idx'])\n",
    "            \n",
    "            unmatched_contour = np.take(possible_contours, unmatched_contour_idx)\n",
    "            \n",
    "            recursive_contour_list = find_chars(unmatched_contour)\n",
    "            \n",
    "            for idx in recursive_contour_list:\n",
    "                matched_result_idx.append(idx)\n",
    "                \n",
    "            break\n",
    "            \n",
    "        return matched_result_idx\n",
    "\n",
    "    result_idx = find_chars(possible_contours)\n",
    "\n",
    "    matched_result = []\n",
    "    for idx_list in result_idx:\n",
    "        matched_result.append(np.take(possible_contours, idx_list))\n",
    "        \n",
    "    temp_result = np.zeros((height, width, channel), dtype=np.uint8)\n",
    "\n",
    "    for r in matched_result:\n",
    "        for d in r:\n",
    "            cv2.rectangle(temp_result, pt1=(d['x'], d['y']), pt2=(d['x']+d['w'], d['y']+d['h']), color=(255,255,255), thickness=2)\n",
    "\n",
    "    PLATE_WIDTH_PADDING = 1.3 # 1.3\n",
    "    PLATE_HEIGHT_PADDING = 1.5 # 1.5\n",
    "    MIN_PLATE_RATIO = 3\n",
    "    MAX_PLATE_RATIO = 10\n",
    "\n",
    "    plate_imgs = []\n",
    "    plate_infos = []\n",
    "\n",
    "    for i, matched_chars in enumerate(matched_result):\n",
    "        sorted_chars = sorted(matched_chars, key=lambda x: x['cx'])\n",
    "\n",
    "        plate_cx = (sorted_chars[0]['cx'] + sorted_chars[-1]['cx']) / 2\n",
    "        plate_cy = (sorted_chars[0]['cy'] + sorted_chars[-1]['cy']) / 2\n",
    "        \n",
    "        plate_width = (sorted_chars[-1]['x'] + sorted_chars[-1]['w'] - sorted_chars[0]['x']) * PLATE_WIDTH_PADDING\n",
    "        \n",
    "        sum_height = 0\n",
    "        for d in sorted_chars:\n",
    "            sum_height += d['h']\n",
    "\n",
    "        plate_height = int(sum_height / len(sorted_chars) * PLATE_HEIGHT_PADDING)\n",
    "        \n",
    "        triangle_height = sorted_chars[-1]['cy'] - sorted_chars[0]['cy']\n",
    "        triangle_hypotenus = np.linalg.norm(\n",
    "            np.array([sorted_chars[0]['cx'], sorted_chars[0]['cy']]) - \n",
    "            np.array([sorted_chars[-1]['cx'], sorted_chars[-1]['cy']])\n",
    "        )\n",
    "        \n",
    "        angle = np.degrees(np.arcsin(triangle_height / triangle_hypotenus))\n",
    "        \n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center=(plate_cx, plate_cy), angle=angle, scale=1.0)\n",
    "        \n",
    "        img_rotated = cv2.warpAffine(img_blur_thresh, M=rotation_matrix, dsize=(width, height))\n",
    "        \n",
    "        img_cropped = cv2.getRectSubPix(\n",
    "            img_rotated, \n",
    "            patchSize=(int(plate_width), int(plate_height)), \n",
    "            center=(int(plate_cx), int(plate_cy))\n",
    "        )\n",
    "        \n",
    "        if img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO or img_cropped.shape[1] / img_cropped.shape[0] < MIN_PLATE_RATIO > MAX_PLATE_RATIO:\n",
    "            continue\n",
    "        \n",
    "        plate_imgs.append(img_cropped)\n",
    "        plate_infos.append({\n",
    "            'x': int(plate_cx - plate_width / 2),\n",
    "            'y': int(plate_cy - plate_height / 2),\n",
    "            'w': int(plate_width),\n",
    "            'h': int(plate_height)\n",
    "        })\n",
    "\n",
    "    longest_idx, longest_text = -1, 0\n",
    "    plate_chars = []\n",
    "\n",
    "    for i, plate_img in enumerate(plate_imgs):\n",
    "        plate_img = cv2.resize(plate_img, dsize=(0, 0), fx=1.6, fy=1.6)\n",
    "        _, plate_img = cv2.threshold(plate_img, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        \n",
    "        # find contours again (same as above)\n",
    "        contours, _ = cv2.findContours(plate_img, mode=cv2.RETR_LIST, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        plate_min_x, plate_min_y = plate_img.shape[1], plate_img.shape[0]\n",
    "        plate_max_x, plate_max_y = 0, 0\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            area = w * h\n",
    "            ratio = w / h\n",
    "\n",
    "            if area > MIN_AREA \\\n",
    "            and w > MIN_WIDTH and h > MIN_HEIGHT \\\n",
    "            and MIN_RATIO < ratio < MAX_RATIO:\n",
    "                if x < plate_min_x:\n",
    "                    plate_min_x = x\n",
    "                if y < plate_min_y:\n",
    "                    plate_min_y = y\n",
    "                if x + w > plate_max_x:\n",
    "                    plate_max_x = x + w\n",
    "                if y + h > plate_max_y:\n",
    "                    plate_max_y = y + h\n",
    "                    \n",
    "        img_result = plate_img[plate_min_y:plate_max_y, plate_min_x:plate_max_x]\n",
    "        \n",
    "        img_result = cv2.GaussianBlur(img_result, ksize=(3, 3), sigmaX=0)\n",
    "        _, img_result = cv2.threshold(img_result, thresh=0.0, maxval=255.0, type=cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "        img_result = cv2.copyMakeBorder(img_result, top=10, bottom=10, left=10, right=10, borderType=cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "        \n",
    "        chars = pytesseract.image_to_string(img_result, lang='kornum+kor', config='--psm 6 preserve_interword_spaces')\n",
    "        #chars = pytesseract.image_to_string(img_result, lang='kornum+kor', config='--psm 7 --oem 3')\n",
    "        \n",
    "        result_chars = ''\n",
    "        has_digit = False\n",
    "        for c in chars:\n",
    "            if ord('Í∞Ä') <= ord(c) <= ord('Ìû£') or c.isdigit():\n",
    "                if c.isdigit():\n",
    "                    has_digit = True\n",
    "                result_chars += c\n",
    "        \n",
    "        plate_chars.append(result_chars)\n",
    "\n",
    "        if has_digit and len(result_chars) > longest_text:\n",
    "            longest_idx = i\n",
    "\n",
    "    return result_chars\n",
    "\n",
    "def is_car_number_in_database(extracted_number, database_numbers):\n",
    "    return any(extracted_number in db_number or db_number in extracted_number for db_number in database_numbers)\n",
    "\n",
    "# Ïú†ÏÇ¨ Î≤àÌò∏Ìåê Ï∞æÍ∏∞ Ìï®Ïàò\n",
    "def find_closest_plate(entering_number, database_numbers):\n",
    "    # ÏûÖÎ†•Îêú Î≤àÌò∏ÌåêÍ≥º Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïùò Î≤àÌò∏ÌåêÏùÑ ÎπÑÍµêÌïòÏó¨ Í∞ÄÏû• Ïú†ÏÇ¨Ìïú Î≤àÌò∏ÌåêÏùÑ Î∞òÌôò\n",
    "    for db_number in database_numbers:\n",
    "        if entering_number in db_number or db_number in entering_number:\n",
    "            return db_number\n",
    "    return None\n",
    "\n",
    "\n",
    "# 2. Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠ & ÎπÑÍµê\n",
    "\n",
    "def img2hash(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (600, 300))\n",
    "    avg = gray.mean()\n",
    "    bi = 1 * (gray > avg)\n",
    "    return bi\n",
    "\n",
    "def hamming_distance(a, b):\n",
    "    a = a.reshape(1,-1)\n",
    "    b = b.reshape(1,-1)\n",
    "    # Í∞ôÏùÄ ÏûêÎ¶¨Ïùò Í∞íÏù¥ ÏÑúÎ°ú Îã§Î•∏ Í≤ÉÎì§Ïùò Ìï©\n",
    "    distance = (a !=b).sum()\n",
    "    return distance\n",
    "\n",
    "matching_criterion = 250\n",
    "desc_criterion = 70\n",
    "def image_match(image, stored_hash):\n",
    "    # Îì§Ïñ¥Ïò® Ï∞®ÎüâÏùò Ïù¥ÎØ∏ÏßÄ\n",
    "    income_car_image = image    \n",
    "    # Ï∞® ÏòÅÏÉÅÏùò Ìï¥Ïâ¨ Íµ¨ÌïòÍ∏∞\n",
    "    query_hash = img2hash(income_car_image)\n",
    "    \n",
    "    # Ìï¥Îãπ Ï∞®ÎüâÏùò Ï†ÄÏû•Îêú Ìï¥Ïâ¨ Î∂àÎü¨Ïò§Í∏∞\n",
    "    stored_hash = stored_hash\n",
    "    \n",
    "    # Ìï¥Î∞ç Í±∞Î¶¨ ÏÇ∞Ï∂ú\n",
    "    flag = 0\n",
    "    hamming_dst = hamming_distance(query_hash, stored_hash)\n",
    "    if hamming_dst/256 < matching_criterion: flag=1; print(f'  ¬∑¬∑¬∑Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠Îüâ : {hamming_dst/256}'); print('  ¬∑¬∑¬∑ÎèôÏùº Ï∞®ÎüâÏûÖÎãàÎã§.')\n",
    "    else: print(f'  ¬∑¬∑¬∑Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠Îüâ : {hamming_dst/256}'); print('  ¬∑¬∑¬∑ÎèôÏùºÌïòÏßÄ ÏïäÏùÄ Ï∞®ÎüâÏûÖÎãàÎã§.')\n",
    "        \n",
    "    return income_car_image, flag\n",
    "\n",
    "\n",
    "\n",
    "# 3. ÌäπÏßïÏ†ê Îß§Ïπ≠ & ÎπÑÍµê\n",
    "\n",
    "# ORBÎ°ú ÏÑúÏà†Ïûê Ï∂îÏ∂ú \n",
    "detector = cv2.ORB_create()\n",
    "# BF-Hamming ÏÉùÏÑ±\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING2)\n",
    "\n",
    "def get_desc(img):\n",
    "    img = img\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kp, desc = detector.detectAndCompute(gray, None)\n",
    "    return kp, desc\n",
    "\n",
    "def ORB_knnMatch(income_car_image, flag, stored_kp, stored_desc):\n",
    "    # Í∞Å ÏòÅÏÉÅÏóê ÎåÄÌï¥ ÌÇ§ Ìè¨Ïù∏Ìä∏ÏôÄ ÏÑúÏà†Ïûê Ï∂îÏ∂ú \n",
    "    compare_kp, compare_desc = get_desc(income_car_image)\n",
    "    # knnMatch, k=2\n",
    "    matches = matcher.knnMatch(compare_desc, stored_desc, 2)\n",
    "\n",
    "    # Ï≤´Î≤àÏû¨ Ïù¥ÏõÉÏùò Í±∞Î¶¨Í∞Ä Îëê Î≤àÏß∏ Ïù¥ÏõÉ Í±∞Î¶¨Ïùò 75% Ïù¥ÎÇ¥Ïù∏ Í≤ÉÎßå Ï∂îÏ∂ú---‚ë§\n",
    "    ratio = 0.75; desc_flag = 0\n",
    "    good_matches = [first for first,second in matches \\\n",
    "                        if first.distance < second.distance * ratio]\n",
    "    if len(good_matches) > desc_criterion: desc_flag = 1; print('  ¬∑¬∑¬∑ÎèôÏùº Ï∞®ÎüâÏûÖÎãàÎã§.')\n",
    "    else: print('  ¬∑¬∑¬∑ÎèôÏùºÌïòÏßÄ ÏïäÏùÄ Ï∞®ÎüâÏûÖÎãàÎã§')\n",
    "    print(f'  ¬∑¬∑¬∑ÌäπÏßïÏ†ê Îß§Ïπ≠Îüâ : {len(good_matches)}/{len(matches)}')\n",
    "    return desc_flag\n",
    "\n",
    "\n",
    "# 4. ÎÇ¥Î∂Ä Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏\n",
    "car1 = cv2.imread('/Users/kyungrim/fake-license-plate-detection/test_car/lightcar1.jpg')\n",
    "car2 = cv2.imread('/Users/kyungrim/fake-license-plate-detection/test_car/whitecar1.jpg')\n",
    "\n",
    "car1_kp, car1_desc = get_desc(car1)\n",
    "car2_kp, car2_desc = get_desc(car2)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ (ÏòàÏãú)\n",
    "database = pd.DataFrame({\n",
    "    'Î≤àÌò∏Ìåê' : [extracting_car_number(car1), extracting_car_number(car2)],\n",
    "    'StoredHash' : [img2hash(car1), img2hash(car2)],\n",
    "    'KeyPoints' : [car1_kp, car2_kp],\n",
    "    'Descriptors' : [car1_desc, car2_desc],\n",
    "    'ÎÇ¥Î∂ÄÏ°¥Ïû¨Ïó¨Î∂Ä' : [0, 0]\n",
    "})\n",
    "\n",
    "\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car :\n",
    "    def __init__(self, img) :\n",
    "        self.car_number = extracting_car_number(img)\n",
    "        self.hash = img2hash(img)\n",
    "        self.kp, self.desc = get_desc(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Îç∞ÏΩîÎ†àÏù¥ÌÑ∞ Ï†ïÏùò\n",
    "def security_check(step_name):\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            global cnt  # Ï†ÑÏó≠ Î≥ÄÏàò cnt Ï†ëÍ∑º\n",
    "            print(f\"Í≤ÄÏÇ¨ ÏãúÏûë: {step_name}\")\n",
    "            result = func(*args, **kwargs)\n",
    "            if result:\n",
    "                print(f\"ÌÜµÍ≥º: {step_name}\")\n",
    "                cnt += 1\n",
    "            else:\n",
    "                print(f\"Ïã§Ìå®: {step_name}\")\n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Î≥¥Ïïà Í≤ÄÏÇ¨ ÏΩîÎìúÏóê Îç∞ÏΩîÎ†àÏù¥ÌÑ∞ Ï†ÅÏö©\n",
    "@security_check(\"Î≤àÌò∏Ìåê Îì±Î°ù Ïó¨Î∂Ä ÌôïÏù∏\")\n",
    "def check_car_registration(car_number, database):\n",
    "    return is_car_number_in_database(car_number, database['Î≤àÌò∏Ìåê'].tolist())\n",
    "\n",
    "@security_check(\"Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠ ÌôïÏù∏\")\n",
    "def check_image_match(car_image, stored_hash):\n",
    "    _, flag = image_match(car_image, stored_hash)\n",
    "    return flag == 1\n",
    "\n",
    "@security_check(\"ÌäπÏßïÏ†ê Îß§Ïπ≠ ÌôïÏù∏\")\n",
    "def check_feature_match(car_image, stored_kp, stored_desc):\n",
    "    return ORB_knnMatch(car_image, 1, stored_kp, stored_desc)  # flagÎäî 1Î°ú ÏÑ§Ï†ï\n",
    "\n",
    "@security_check(\"ÎÇ¥Î∂Ä Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏\")\n",
    "def check_internal_presence(closest_plate, database):\n",
    "    return database.loc[database['Î≤àÌò∏Ìåê'] == closest_plate, 'ÎÇ¥Î∂ÄÏ°¥Ïû¨Ïó¨Î∂Ä'].values[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏßÑÏûÖÌïú Ï∞®ÎüâÏùò ÏÇ¨ÏßÑÏùÑ ÏóÖÎ°úÎìú Ìï¥Ï£ºÏÑ∏Ïöî.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏßÑÏûÖÌïú Ï∞®ÎüâÏùò Î≤àÌò∏Ìåê: 157Î™®48761\n",
      "Í≤ÄÏÇ¨ ÏãúÏûë: Î≤àÌò∏Ìåê Îì±Î°ù Ïó¨Î∂Ä ÌôïÏù∏\n",
      "ÌÜµÍ≥º: Î≤àÌò∏Ìåê Îì±Î°ù Ïó¨Î∂Ä ÌôïÏù∏\n",
      "Í≤ÄÏÇ¨ ÏãúÏûë: Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠ ÌôïÏù∏\n",
      "  ¬∑¬∑¬∑Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠Îüâ : 205.078125\n",
      "  ¬∑¬∑¬∑ÎèôÏùº Ï∞®ÎüâÏûÖÎãàÎã§.\n",
      "ÌÜµÍ≥º: Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠ ÌôïÏù∏\n",
      "Í≤ÄÏÇ¨ ÏãúÏûë: ÌäπÏßïÏ†ê Îß§Ïπ≠ ÌôïÏù∏\n",
      "  ¬∑¬∑¬∑ÎèôÏùº Ï∞®ÎüâÏûÖÎãàÎã§.\n",
      "  ¬∑¬∑¬∑ÌäπÏßïÏ†ê Îß§Ïπ≠Îüâ : 94/500\n",
      "ÌÜµÍ≥º: ÌäπÏßïÏ†ê Îß§Ïπ≠ ÌôïÏù∏\n",
      "Í≤ÄÏÇ¨ ÏãúÏûë: ÎÇ¥Î∂Ä Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏\n",
      "ÌÜµÍ≥º: ÎÇ¥Î∂Ä Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏\n",
      "üöò Î™®Îì† Î≥¥ÏïàÏùÑ ÌÜµÍ≥ºÌñàÏäµÎãàÎã§. ÏßÑÏûÖÌïòÏã≠ÏãúÏò§. üöò\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungrim/fake-license-plate-detection/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "print(\"ÏßÑÏûÖÌïú Ï∞®ÎüâÏùò ÏÇ¨ÏßÑÏùÑ ÏóÖÎ°úÎìú Ìï¥Ï£ºÏÑ∏Ïöî.\")\n",
    "car_image = imread('/Users/kyungrim/fake-license-plate-detection/test_car/lightcar2.jpg')\n",
    "entering_car = Car(car_image)\n",
    "cnt = 0  # ÌÜµÍ≥º Îã®Í≥Ñ count\n",
    "\n",
    "# Î≤àÌò∏Ìåê Ïù∏Ïãù\n",
    "cropped_plate = detecting_car_plate(car_image)\n",
    "car_number = entering_car.car_number\n",
    "if car_number:\n",
    "    print(\"ÏßÑÏûÖÌïú Ï∞®ÎüâÏùò Î≤àÌò∏Ìåê:\", car_number)\n",
    "\n",
    "# 1. Î≤àÌò∏Ìåê Îì±Î°ù Ïó¨Î∂Ä ÌôïÏù∏\n",
    "check_car_registration(car_number, database)\n",
    "\n",
    "# Í∞ÄÏû• Ïú†ÏÇ¨Ìïú Î≤àÌò∏Ìåê Ï∞æÍ∏∞\n",
    "closest_plate = find_closest_plate(car_number, database['Î≤àÌò∏Ìåê'].tolist())\n",
    "\n",
    "# 2. Ïù¥ÎØ∏ÏßÄ Îß§Ïπ≠ ÌôïÏù∏\n",
    "stored_hash = database.loc[database['Î≤àÌò∏Ìåê'] == closest_plate, 'StoredHash'].values[0]\n",
    "check_image_match(car_image, stored_hash)\n",
    "\n",
    "# 3. ÌäπÏßïÏ†ê Îß§Ïπ≠ ÌôïÏù∏\n",
    "stored_kp = database.loc[database['Î≤àÌò∏Ìåê'] == closest_plate, 'KeyPoints'].values[0]\n",
    "stored_desc = database.loc[database['Î≤àÌò∏Ìåê'] == closest_plate, 'Descriptors'].values[0]\n",
    "check_feature_match(car_image, stored_kp, stored_desc)\n",
    "\n",
    "# 4. ÎÇ¥Î∂Ä Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏\n",
    "check_internal_presence(closest_plate, database)\n",
    "\n",
    "# ÏµúÏ¢Ö ÏßÑÏûÖ Ïó¨Î∂Ä ÌåêÎã®\n",
    "if cnt == 4:\n",
    "    print(\"üöò Î™®Îì† Î≥¥ÏïàÏùÑ ÌÜµÍ≥ºÌñàÏäµÎãàÎã§. ÏßÑÏûÖÌïòÏã≠ÏãúÏò§. üöò\")\n",
    "else:\n",
    "    print(\"‚ùå Î≥¥ÏïàÏùÑ ÌÜµÍ≥ºÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§. Ï∂úÏ∞®ÌïòÏã≠ÏãúÏò§. ‚ùå\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
